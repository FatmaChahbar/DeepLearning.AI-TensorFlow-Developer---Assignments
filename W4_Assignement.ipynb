{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6KoxTM3yG/Ut1Y/oFpsaw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatmaChahbar/MachineLearning_Projects/blob/main/W4_Assignement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zzCPyrxK4H5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "happy_dir = \"./data/happy/\"\n",
        "sad_dir = \"./data/sad/\"\n",
        "\n",
        "print(\"Sample happy image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\"))\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSample sad image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(sad_dir, os.listdir(sad_dir)[0])}\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3YbVI6BFTJVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Load the first example of a happy face\n",
        "sample_image  = load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\")\n",
        "\n",
        "# Convert the image into its numpy array representation\n",
        "sample_array = img_to_array(sample_image)\n",
        "\n",
        "print(f\"Each image has shape: {sample_array.shape}\")\n",
        "\n",
        "print(f\"The maximum pixel value used is: {np.max(sample_array)}\")"
      ],
      "metadata": {
        "id": "D0uMMniZTNDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.999:\n",
        "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ],
      "metadata": {
        "id": "el3tQfFsTQUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# GRADED FUNCTION: image_generator\n",
        "def image_generator():\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Instantiate the ImageDataGenerator class.\n",
        "    # Remember to set the rescale argument.\n",
        "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "    # Specify the method to load images from a directory and pass in the appropriate arguments:\n",
        "    # - directory: should be a relative path to the directory containing the data\n",
        "    # - targe_size: set this equal to the resolution of each image (excluding the color dimension)\n",
        "    # - batch_size: number of images the generator yields when asked for a next batch. Set this to 10.\n",
        "    # - class_mode: How the labels are represented. Should be one of sample_image \", \"categorical\" or \"sparse\".\n",
        "    #               Pick the one that better suits here given that the labels are going to be 1D binary labels.\n",
        "    train_generator = train_datagen.flow_from_directory(directory=data_path,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=10,\n",
        "                                                        class_mode='binary')\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return train_generator"
      ],
      "metadata": {
        "id": "fyuWfUn8LBDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your generator in a variable\n",
        "gen = image_generator()\n",
        "\n",
        "# Expected output: 'Found 80 images belonging to 2 classes'"
      ],
      "metadata": {
        "id": "i2rrr3EqTUl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers, losses\n",
        "\n",
        "# GRADED FUNCTION: train_happy_sad_model\n",
        "def train_happy_sad_model(train_generator):\n",
        "\n",
        "    # Instantiate the callback\n",
        "    callbacks = myCallback()\n",
        "\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Define the model, you can toy around with the architecture.\n",
        "    # Some helpful tips in case you are stuck:\n",
        "    \n",
        "    # - A good first layer would be a Conv2D layer with an input shape that matches \n",
        "    #   that of every image in the training set (including the color dimension)\n",
        "\n",
        "    # - The model will work best with 3 convolutional layers\n",
        "\n",
        "    # - There should be a Flatten layer in between convolutional and dense layers\n",
        "\n",
        "    # - The final layer should be a Dense layer with the number of units \n",
        "    #   and activation function that supports binary classification.\n",
        "\n",
        "    model = tf.keras.models.Sequential([ \n",
        "      tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),# Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    # Select a loss function compatible with the last layer of your network\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=RMSprop(learning_rate=0.001),\n",
        "                  metrics=['accuracy']) \n",
        "    \n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    # Your model should achieve the desired accuracy in less than 15 epochs.\n",
        "    # You can hardcode up to 20 epochs in the function below but the callback should trigger before 15.\n",
        "    history = model.fit(x=train_generator,\n",
        "                        epochs=20,\n",
        "                        callbacks=[callbacks]\n",
        "                       ) \n",
        "    \n",
        "    ### END CODE HERE\n",
        "    return history"
      ],
      "metadata": {
        "id": "4HmiFJLELBGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = train_happy_sad_model(gen)\n"
      ],
      "metadata": {
        "id": "b-fzJWPkLBPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Your model reached the desired accuracy after {len(hist.epoch)} epochs\")\n"
      ],
      "metadata": {
        "id": "J4g7aG6yLBSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fW2IiKnwLBU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xiUJhU0sLBYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQqRHb0vLBbU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}